{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d6234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/leonwong/anaconda3/envs/wds/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#ä½¿ç”¨text_to_word_sequenceæ‹†åˆ†å•è¯\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219d9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_en = \"Tomorrow is another day@priscillachan728 is one of my most favorite song.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896b96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_zh = 'ã€ä½ çŸ¥é“#å¤§ç†ŠçŒ«æœ‰å‡ æ ¹æ‰‹æŒ‡#å—ï¼Ÿ ï¼š-ã€‘è¿˜æœ‰ï¼Œ#å¤§ç†ŠçŒ«çš„æ‰‹æŒ‡æ˜¯ä»€ä¹ˆé¢œè‰²#ï¼Ÿå¿«æˆ³è§†é¢‘ğŸ‘‡æ‰¾ç­”æ¡ˆ@Pandafulç†ŠçŒ«ç¤¾åŒº #å¤§ç†ŠçŒ«å°çŸ¥è¯†#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9852fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_tokens(text):\n",
    "    return text_to_word_sequence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c207c3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomorrow',\n",
       " 'is',\n",
       " 'another',\n",
       " 'day',\n",
       " 'priscillachan728',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'most',\n",
       " 'favorite',\n",
       " 'song']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_tokens(sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad34ea46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ã€ä½ çŸ¥é“',\n",
       " 'å¤§ç†ŠçŒ«æœ‰å‡ æ ¹æ‰‹æŒ‡',\n",
       " 'å—ï¼Ÿ',\n",
       " 'ï¼š',\n",
       " 'ã€‘è¿˜æœ‰ï¼Œ',\n",
       " 'å¤§ç†ŠçŒ«çš„æ‰‹æŒ‡æ˜¯ä»€ä¹ˆé¢œè‰²',\n",
       " 'ï¼Ÿå¿«æˆ³è§†é¢‘ğŸ‘‡æ‰¾ç­”æ¡ˆ',\n",
       " 'pandafulç†ŠçŒ«ç¤¾åŒº',\n",
       " 'å¤§ç†ŠçŒ«å°çŸ¥è¯†']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keras_tokens(sentence_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366b2f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ä½ çŸ¥é“',\n",
       " 'å¤§ç†ŠçŒ«æœ‰å‡ æ ¹æ‰‹æŒ‡',\n",
       " 'å—',\n",
       " 'è¿˜æœ‰',\n",
       " 'å¤§ç†ŠçŒ«çš„æ‰‹æŒ‡æ˜¯ä»€ä¹ˆé¢œè‰²',\n",
       " 'å¿«æˆ³è§†é¢‘',\n",
       " 'æ‰¾ç­”æ¡ˆ',\n",
       " 'pandafulç†ŠçŒ«ç¤¾åŒº',\n",
       " 'å¤§ç†ŠçŒ«å°çŸ¥è¯†']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sentence_zh = re.sub(r'([^\\s\\w]|_)+', ' ', sentence_zh)\n",
    "\n",
    "get_keras_tokens(sentence_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2798e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#ç»Ÿè®¡æ‹†åˆ†åçš„å•è¯æ•°é‡\n",
    "vocab_en_size = len(get_keras_tokens(sentence_en))\n",
    "print(vocab_en_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c3a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "vocab_zh_size = len(get_keras_tokens(sentence_zh))\n",
    "print(vocab_zh_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f1d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ–‡æœ¬å‘é‡åŒ–\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#åˆ›å»ºåˆ†è¯å™¨Tokenizerå¯¹è±¡\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#æä¾›è®­ç»ƒè¯­æ–™åº“ï¼Œæ‰‹åŠ¨åˆ†è¯ï¼Œä½¿ç”¨ç©ºæ ¼ä½œä¸ºåˆ†è¯ç¬¦\n",
    "text = [\"ä½ çŸ¥é“ å¤§ç†ŠçŒ« æœ‰ å‡ æ ¹ æ‰‹æŒ‡\",\n",
    "        \"å¤§ç†ŠçŒ« æ‰‹æŒ‡ ä»€ä¹ˆé¢œè‰²\",\n",
    "         \"å¿«æˆ³è§†é¢‘ æ‰¾ç­”æ¡ˆ\",\n",
    "         \"pandaful ç†ŠçŒ«ç¤¾åŒº\",\n",
    "         \"å¤§ç†ŠçŒ« å°çŸ¥è¯†\"]\n",
    "\n",
    "#fit_on_textsæ–¹æ³•\n",
    "tokenizer.fit_on_texts(text)\n",
    "#å®ŒæˆåµŒå…¥åï¼ŒTokenizeræä¾›äº†å››ä¸ªå±æ€§ï¼Œå¯ä»¥ä½¿ç”¨å®ƒä»¬æ¥æŸ¥è¯¢æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391dec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ä½ çŸ¥é“', 1),\n",
       "             ('å¤§ç†ŠçŒ«', 3),\n",
       "             ('æœ‰', 1),\n",
       "             ('å‡ æ ¹', 1),\n",
       "             ('æ‰‹æŒ‡', 2),\n",
       "             ('ä»€ä¹ˆé¢œè‰²', 1),\n",
       "             ('å¿«æˆ³è§†é¢‘', 1),\n",
       "             ('æ‰¾ç­”æ¡ˆ', 1),\n",
       "             ('pandaful', 1),\n",
       "             ('ç†ŠçŒ«ç¤¾åŒº', 1),\n",
       "             ('å°çŸ¥è¯†', 1)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_counts\n",
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fb95a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'æœ‰': 1,\n",
       "             'å‡ æ ¹': 1,\n",
       "             'ä½ çŸ¥é“': 1,\n",
       "             'æ‰‹æŒ‡': 2,\n",
       "             'å¤§ç†ŠçŒ«': 3,\n",
       "             'ä»€ä¹ˆé¢œè‰²': 1,\n",
       "             'å¿«æˆ³è§†é¢‘': 1,\n",
       "             'æ‰¾ç­”æ¡ˆ': 1,\n",
       "             'pandaful': 1,\n",
       "             'ç†ŠçŒ«ç¤¾åŒº': 1,\n",
       "             'å°çŸ¥è¯†': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_docs\n",
    "tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8681593a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'å¤§ç†ŠçŒ«': 1,\n",
       " 'æ‰‹æŒ‡': 2,\n",
       " 'ä½ çŸ¥é“': 3,\n",
       " 'æœ‰': 4,\n",
       " 'å‡ æ ¹': 5,\n",
       " 'ä»€ä¹ˆé¢œè‰²': 6,\n",
       " 'å¿«æˆ³è§†é¢‘': 7,\n",
       " 'æ‰¾ç­”æ¡ˆ': 8,\n",
       " 'pandaful': 9,\n",
       " 'ç†ŠçŒ«ç¤¾åŒº': 10,\n",
       " 'å°çŸ¥è¯†': 11}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_index\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40ed2784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#document_count\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ef5e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 10, 11, 1, 4, 5, 2]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizerå¤ç”¨å®ç°è‡ªåŠ¨ç¼–ç \n",
    "new_text = [\"pandaful ç†ŠçŒ«ç¤¾åŒº å°çŸ¥è¯† å¤§ç†ŠçŒ« æœ‰ å‡ æ ¹ æ‰‹æŒ‡\"]\n",
    "tokenizer.texts_to_sequences(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0ee06f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  9, 10, 11,  1,  4,  5,  2]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ä¸ºè¾“å…¥æ·±åº¦å­¦ä¹ æ¨¡å‹ä½œå‡†å¤‡\n",
    "#kerasåªèƒ½æ¥å—é•¿åº¦ç›¸åŒçš„åºåˆ—è¾“å…¥ï¼Œå¦‚æœç›®å‰åºåˆ—é•¿åº¦å‚å·®ä¸é½ï¼Œéœ€è¦ä½¿ç”¨\n",
    "#pad_sequences()\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#è¿›è¡Œäº†è¡¥å…¨\n",
    "pad_sequences(tokenizer.texts_to_sequences(new_text), maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34643b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ä½¿ç”¨TextBlobè¿›è¡Œåˆ†è¯\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk import data\n",
    "data.path.append(\"/Users/leonwong/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4cc446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_textblob_tokens(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfa5be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Tomorrow', 'is', 'another', 'day', 'priscillachan728', 'is', 'one', 'of', 'my', 'most', 'favorite', 'song'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_textblob_tokens(sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c47349dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['ä½ çŸ¥é“', 'å¤§ç†ŠçŒ«æœ‰å‡ æ ¹æ‰‹æŒ‡', 'å—', 'è¿˜æœ‰', 'å¤§ç†ŠçŒ«çš„æ‰‹æŒ‡æ˜¯ä»€ä¹ˆé¢œè‰²', 'å¿«æˆ³è§†é¢‘', 'æ‰¾ç­”æ¡ˆ', 'Pandafulç†ŠçŒ«ç¤¾åŒº', 'å¤§ç†ŠçŒ«å°çŸ¥è¯†'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_textblob_tokens(sentence_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0674c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
